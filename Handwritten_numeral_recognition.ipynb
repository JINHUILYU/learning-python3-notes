{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-16T07:01:30.890282200Z",
     "start_time": "2023-11-16T06:59:05.141849800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 28, 28]             320\n",
      "              ReLU-2           [-1, 32, 28, 28]               0\n",
      "         MaxPool2d-3           [-1, 32, 14, 14]               0\n",
      "            Conv2d-4           [-1, 64, 14, 14]          18,496\n",
      "              ReLU-5           [-1, 64, 14, 14]               0\n",
      "         MaxPool2d-6             [-1, 64, 7, 7]               0\n",
      "            Linear-7                  [-1, 128]         401,536\n",
      "              ReLU-8                  [-1, 128]               0\n",
      "            Linear-9                   [-1, 10]           1,290\n",
      "================================================================\n",
      "Total params: 421,642\n",
      "Trainable params: 421,642\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.65\n",
      "Params size (MB): 1.61\n",
      "Estimated Total Size (MB): 2.26\n",
      "----------------------------------------------------------------\n",
      "Epoch [1/10], Test Accuracy: 98.38%, Time: 14.3534s, Best Accuracy: 98.38% at epoch 1\n",
      "Epoch [2/10], Test Accuracy: 98.86%, Time: 15.3133s, Best Accuracy: 98.86% at epoch 2\n",
      "Epoch [3/10], Test Accuracy: 98.97%, Time: 14.9736s, Best Accuracy: 98.97% at epoch 3\n",
      "Epoch [4/10], Test Accuracy: 98.89%, Time: 14.1363s, Best Accuracy: 98.97% at epoch 3\n",
      "Epoch [5/10], Test Accuracy: 99.02%, Time: 13.7947s, Best Accuracy: 99.02% at epoch 5\n",
      "Epoch [6/10], Test Accuracy: 99.09%, Time: 13.8379s, Best Accuracy: 99.09% at epoch 6\n",
      "Epoch [7/10], Test Accuracy: 98.96%, Time: 14.2416s, Best Accuracy: 99.09% at epoch 6\n",
      "Epoch [8/10], Test Accuracy: 99.23%, Time: 14.7723s, Best Accuracy: 99.23% at epoch 8\n",
      "Epoch [9/10], Test Accuracy: 98.94%, Time: 14.6565s, Best Accuracy: 99.23% at epoch 8\n",
      "Epoch [10/10], Test Accuracy: 99.10%, Time: 14.6063s, Best Accuracy: 99.23% at epoch 8\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchsummary import summary\n",
    "import time\n",
    "import os\n",
    "\n",
    "\n",
    "# 定义卷积神经网络模型\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.fc1 = nn.Linear(7 * 7 * 64, 128)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# 设置随机种子以保证结果可重复\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# 加载MNIST数据集并进行预处理\n",
    "train_dataset = MNIST(root='./data', train=True, download=True, transform=ToTensor())\n",
    "test_dataset = MNIST(root='./data', train=False, download=True, transform=ToTensor())\n",
    "\n",
    "# 创建数据加载器\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# 创建模型实例并打印模型结构\n",
    "model = CNN()\n",
    "summary(model, (1, 28, 28))\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 训练模型\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "num_epochs = 10\n",
    "best_acc = 0.0\n",
    "best_epoch = 0\n",
    "checkpoints = './checkpoints'\n",
    "\n",
    "if not os.path.exists(checkpoints):\n",
    "    os.makedirs(checkpoints)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # 设置计时器，计算每个epoch的用时\n",
    "    start_time = time.time()\n",
    "    model.train()  # 保证每一个batch都能进入model.train()的模式\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    # 记录验证集上准确率最高的模型\n",
    "    best_model_path = checkpoints + \"/\" + 'best_model' + '.pth'\n",
    "    if accuracy >= best_acc:\n",
    "        best_acc = accuracy\n",
    "        best_epoch = epoch\n",
    "        torch.save(model, best_model_path)\n",
    "    end_time = time.time()\n",
    "    print(\n",
    "        f\"Epoch [{epoch + 1}/{num_epochs}], Test Accuracy: {accuracy:.2f}%, Time: {end_time - start_time:.4f}s, Best Accuracy: {best_acc:.2f}% at epoch {best_epoch + 1}\")\n",
    "# 保存最后的模型\n",
    "torch.save(model, checkpoints + '/last.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can't get attribute 'CNN' on <module '__main__'>",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[27], line 38\u001B[0m\n\u001B[0;32m     36\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m__main__\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m     37\u001B[0m     img_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmnist/1/1.jpg\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m---> 38\u001B[0m     pred \u001B[38;5;241m=\u001B[39m Pred()\n\u001B[0;32m     39\u001B[0m     res \u001B[38;5;241m=\u001B[39m pred\u001B[38;5;241m.\u001B[39mpredict(img_path)\n\u001B[0;32m     40\u001B[0m     image \u001B[38;5;241m=\u001B[39m Image\u001B[38;5;241m.\u001B[39mopen(img_path)\n",
      "Cell \u001B[1;32mIn[27], line 9\u001B[0m, in \u001B[0;36mPred.__init__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m      7\u001B[0m model_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcheckpoints/best_model.pth\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;66;03m# 加载模型\u001B[39;00m\n\u001B[1;32m----> 9\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mload(model_path)\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mdevice(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgpu\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mis_available() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\serialization.py:1014\u001B[0m, in \u001B[0;36mload\u001B[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001B[0m\n\u001B[0;32m   1012\u001B[0m             \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m   1013\u001B[0m                 \u001B[38;5;28;01mraise\u001B[39;00m pickle\u001B[38;5;241m.\u001B[39mUnpicklingError(UNSAFE_MESSAGE \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(e)) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m-> 1014\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m _load(opened_zipfile,\n\u001B[0;32m   1015\u001B[0m                      map_location,\n\u001B[0;32m   1016\u001B[0m                      pickle_module,\n\u001B[0;32m   1017\u001B[0m                      overall_storage\u001B[38;5;241m=\u001B[39moverall_storage,\n\u001B[0;32m   1018\u001B[0m                      \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpickle_load_args)\n\u001B[0;32m   1019\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m mmap:\n\u001B[0;32m   1020\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmmap can only be used with files saved with \u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   1021\u001B[0m                        \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`torch.save(_use_new_zipfile_serialization=True), \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1022\u001B[0m                        \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mplease torch.save your checkpoint with this option in order to use mmap.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\serialization.py:1422\u001B[0m, in \u001B[0;36m_load\u001B[1;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001B[0m\n\u001B[0;32m   1420\u001B[0m unpickler \u001B[38;5;241m=\u001B[39m UnpicklerWrapper(data_file, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpickle_load_args)\n\u001B[0;32m   1421\u001B[0m unpickler\u001B[38;5;241m.\u001B[39mpersistent_load \u001B[38;5;241m=\u001B[39m persistent_load\n\u001B[1;32m-> 1422\u001B[0m result \u001B[38;5;241m=\u001B[39m unpickler\u001B[38;5;241m.\u001B[39mload()\n\u001B[0;32m   1424\u001B[0m torch\u001B[38;5;241m.\u001B[39m_utils\u001B[38;5;241m.\u001B[39m_validate_loaded_sparse_tensors()\n\u001B[0;32m   1425\u001B[0m torch\u001B[38;5;241m.\u001B[39m_C\u001B[38;5;241m.\u001B[39m_log_api_usage_metadata(\n\u001B[0;32m   1426\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtorch.load.metadata\u001B[39m\u001B[38;5;124m\"\u001B[39m, {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mserialization_id\u001B[39m\u001B[38;5;124m\"\u001B[39m: zip_file\u001B[38;5;241m.\u001B[39mserialization_id()}\n\u001B[0;32m   1427\u001B[0m )\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\serialization.py:1415\u001B[0m, in \u001B[0;36m_load.<locals>.UnpicklerWrapper.find_class\u001B[1;34m(self, mod_name, name)\u001B[0m\n\u001B[0;32m   1413\u001B[0m         \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[0;32m   1414\u001B[0m mod_name \u001B[38;5;241m=\u001B[39m load_module_mapping\u001B[38;5;241m.\u001B[39mget(mod_name, mod_name)\n\u001B[1;32m-> 1415\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mfind_class(mod_name, name)\n",
      "\u001B[1;31mAttributeError\u001B[0m: Can't get attribute 'CNN' on <module '__main__'>"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "\n",
    "# 预测类\n",
    "class Pred:\n",
    "    def __init__(self):\n",
    "        self.labels = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "        model_path = 'checkpoints/best_model.pth'\n",
    "        # 加载模型\n",
    "        self.model = torch.load(model_path)\n",
    "        self.device = torch.device('gpu' if torch.cuda.is_available() else 'cpu')\n",
    "        self.model = self.model.to(self.device)\n",
    "\n",
    "    # 预测\n",
    "    def predict(self, img_path):\n",
    "        transform = transforms.Compose([\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "        img = Image.open(img_path)\n",
    "        img = img.convert('RGB')\n",
    "        img = transform(img)\n",
    "        img.resize_(1, 3, 28, 28)\n",
    "        img = img.view(1, 3, 28, 28).to(self.device)\n",
    "        output = self.model(img)\n",
    "        output = torch.softmax(output, dim=1)\n",
    "        # 每个预测值的概率\n",
    "        probability = output.cpu().detach().numpy()[0]\n",
    "        # 找出最大概率值的索引\n",
    "        output = torch.argmax(output, dim=1)\n",
    "        index = output.cpu().numpy()[0]\n",
    "        # 预测结果\n",
    "        pred = self.labels[index]\n",
    "        print(pred, probability[index])\n",
    "        return pred\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    img_path = 'mnist/1/1.jpg'\n",
    "    pred = Pred()\n",
    "    res = pred.predict(img_path)\n",
    "    image = Image.open(img_path)\n",
    "    image.show()\n",
    "    print(res)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-16T06:58:50.035433600Z",
     "start_time": "2023-11-16T06:58:47.967269200Z"
    }
   },
   "id": "72817422382d0c08"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import os\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import mnist\n",
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "train_data = mnist.MNIST('mnist', train=True, transform=transforms.ToTensor(), download=True)\n",
    "test_data = mnist.MNIST('mnist', train=False, transform=transforms.ToTensor(), download=True)\n",
    "train_loader = data.DataLoader(dataset=train_data, batch_size=1, shuffle=True)\n",
    "test_loader = data.DataLoader(dataset=test_data, batch_size=1, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T08:46:17.454684800Z",
     "start_time": "2023-11-15T08:46:17.380050800Z"
    }
   },
   "id": "593b9663f7186eda"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def show():\n",
    "    plt.figure(figsize=(16, 9))\n",
    "    for i, item in enumerate(itertools.islice(train_loader, 2, 102)):\n",
    "        plt.subplot(10, 10, i + 1)\n",
    "        img, label = item\n",
    "        img = img[0].cpu().numpy()\n",
    "        array = (img.reshape((28, 28)) * 255).astype(np.uint8)\n",
    "        img = Image.fromarray(array, 'L')\n",
    "        label = label.cpu().numpy()[0]\n",
    "        plt.imshow(img, cmap=plt.get_cmap('gray'))\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T08:46:21.125013600Z",
     "start_time": "2023-11-15T08:46:21.108505Z"
    }
   },
   "id": "dc5211b5db5cdca4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.transforms import ToTensor\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "# 定义卷积神经网络模型\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.fc1 = nn.Linear(7 * 7 * 64, 128)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# 设置随机种子以保证结果可重复\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# 加载MNIST数据集并进行预处理\n",
    "train_dataset = MNIST(root='./data', train=True, download=True, transform=ToTensor())\n",
    "test_dataset = MNIST(root='./data', train=False, download=True, transform=ToTensor())\n",
    "\n",
    "# 创建数据加载器\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# 创建模型实例并打印模型结构\n",
    "model = CNN()\n",
    "summary(model, (1, 28, 28))\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 训练模型\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "num_epochs = 10\n",
    "best_acc = 0.0\n",
    "best_epoch = 0\n",
    "checkpoints = './checkpoints'\n",
    "\n",
    "if not os.path.exists(checkpoints):\n",
    "    os.makedirs(checkpoints)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # 设置计时器，计算每个epoch的用时\n",
    "    start_time = time.time()\n",
    "    model.train()  # 保证每一个batch都能进入model.train()的模式\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    # 记录验证集上准确率最高的模型\n",
    "    best_model_path = checkpoints + \"/\" + 'best_model' + '.pth'\n",
    "    if accuracy >= best_acc:\n",
    "        best_acc = accuracy\n",
    "        best_epoch = epoch\n",
    "        torch.save(model, best_model_path)\n",
    "    end_time = time.time()\n",
    "    print(\n",
    "        f\"Epoch [{epoch + 1}/{num_epochs}], Test Accuracy: {accuracy:.2f}%, Time: {end_time - start_time:.4f}s, Best Accuracy: {best_acc:.2f}% at epoch {best_epoch + 1}\")\n",
    "# 保存最后的模型\n",
    "torch.save(model, checkpoints + '/last.pt')\n",
    "\n",
    "# 加载训练好的模型\n",
    "model = CNN()\n",
    "model.load_state_dict(torch.load('checkpoints/best_model.pth'))\n",
    "model.eval()\n",
    "\n",
    "# 加载手写数字图片并进行预处理\n",
    "image = Image.open('handwritten_digit.png').convert('L')  # 读取手写数字图片并转为灰度图像\n",
    "image = ToTensor()(image)  # 转换为Tensor格式\n",
    "image = image.unsqueeze(0)  # 添加batch维度\n",
    "\n",
    "# 使用模型进行预测\n",
    "with torch.no_grad():\n",
    "    prediction = model(image)\n",
    "    _, predicted_label = torch.max(prediction, 1)\n",
    "\n",
    "print(\"Predicted Label:\", predicted_label.item())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-15T11:48:10.775759700Z"
    }
   },
   "id": "6ec9041b0db65787"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "# excel\n",
    "import openpyxl\n",
    "import os\n",
    "\n",
    "# 打开Excel文件\n",
    "if not os.path.exists('data.xlsx'):\n",
    "    workbook = openpyxl.Workbook()\n",
    "else:\n",
    "    workbook = openpyxl.load_workbook('data.xlsx')\n",
    "\n",
    "# 选择要操作的工作表\n",
    "if 'Sheet1' in workbook.sheetnames:\n",
    "    worksheet = workbook['Sheet1']\n",
    "else:\n",
    "    worksheet = workbook.create_sheet('Sheet1')\n",
    "\n",
    "# 打开文本文件\n",
    "with open('ChatGPT.txt', 'r', encoding='UTF-8') as file:\n",
    "    # 逐行读取文本文件内容\n",
    "    lines = file.readlines()\n",
    "    i = 1\n",
    "    # 逐行写入Excel表格\n",
    "    for _, line in enumerate(lines):\n",
    "        if line == '\\n':  # 如果是空行，则跳过\n",
    "            continue\n",
    "        # 获取要写入的单元格位置\n",
    "        cell = worksheet.cell(row=i + 1, column=3)\n",
    "        # 写入数据\n",
    "        cell.value = line.strip()  # 去除行末尾的换行符\n",
    "        i += 1\n",
    "\n",
    "with open('NewBing.txt', 'r', encoding='UTF-8') as file:\n",
    "    # 逐行读取文本文件内容\n",
    "    lines = file.readlines()\n",
    "    i = 1\n",
    "    # 逐行写入Excel表格\n",
    "    for _, line in enumerate(lines):\n",
    "        if line == '\\n':  # 如果是空行，则跳过\n",
    "            continue\n",
    "        # 获取要写入的单元格位置\n",
    "        cell = worksheet.cell(row=i + 1, column=4)\n",
    "        # 写入数据\n",
    "        cell.value = line.strip()  # 去除行末尾的换行符\n",
    "        i += 1\n",
    "\n",
    "# 保存Excel文件\n",
    "workbook.save('data.xlsx')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-16T06:00:49.033623900Z",
     "start_time": "2023-11-16T06:00:49.002208900Z"
    }
   },
   "id": "fe26d21acdbf2f08"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "内容写入文件成功\n"
     ]
    }
   ],
   "source": [
    "# txt\n",
    "try:\n",
    "    with open(\"source.txt\", \"r\", encoding='utf-8') as source:\n",
    "        f = open(\"target.txt\", \"w\", encoding='utf-8')\n",
    "        lines = source.readlines()\n",
    "        for line in lines:\n",
    "            if line == '\\n':\n",
    "                continue\n",
    "            else:\n",
    "                f.write(line)\n",
    "except IOError:\n",
    "    print(\"Error: 没有找到文件或读取文件失败\")\n",
    "else:\n",
    "    print(\"内容写入文件成功\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-21T10:58:11.346111500Z",
     "start_time": "2023-11-21T10:58:11.328193700Z"
    }
   },
   "id": "bc166410cf3c7817"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "NameError: name 'hello' is not defined\n"
     ]
    }
   ],
   "source": [
    "s = 'hello'\n",
    "print(eval(\"s\"))  # eval()去除字符串的引号\n",
    "try:\n",
    "    print(eval(s))  # s去除引号后，变成了变量名，所以会报错\n",
    "except NameError:\n",
    "    print(\"NameError: name 'hello' is not defined\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-21T11:40:11.691052500Z",
     "start_time": "2023-11-21T11:40:11.689540200Z"
    }
   },
   "id": "ec08629822bcc890"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "满分\n"
     ]
    }
   ],
   "source": [
    "# 模式匹配\n",
    "score = input(\"请输入成绩：\")\n",
    "match score:\n",
    "    case \"A\":\n",
    "        print(\"满分\")\n",
    "    case \"B\":\n",
    "        print(\"优秀\")\n",
    "    case \"C\":\n",
    "        print(\"良好\")\n",
    "    case \"D\":\n",
    "        print(\"中等\")\n",
    "    case \"E\":\n",
    "        print(\"及格\")\n",
    "    case _:  # _表示匹配所有其他情况\n",
    "        print(\"不及格\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-21T11:42:58.979251500Z",
     "start_time": "2023-11-21T11:42:57.486368600Z"
    }
   },
   "id": "df6e998e906e1bfc"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1988, 1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 2000, 2001]\n"
     ]
    }
   ],
   "source": [
    "nums = [88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 0, 1]\n",
    "for i in range(0, len(nums)):\n",
    "    if nums[i] // 10 != 0:\n",
    "        nums[i] += 1900\n",
    "    else:\n",
    "        nums[i] += 2000\n",
    "print(nums)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-21T11:52:01.776758700Z",
     "start_time": "2023-11-21T11:52:01.763807500Z"
    }
   },
   "id": "fcaf45b8d3f45788"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1988, 1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 2000, 2001]\n"
     ]
    }
   ],
   "source": [
    "nums = [88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 0, 1]\n",
    "for index, value in enumerate(nums):\n",
    "    if value // 10 != 0:\n",
    "        nums[index] += 1900\n",
    "    else:\n",
    "        nums[index] += 2000\n",
    "print(nums)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-21T11:54:13.478875900Z",
     "start_time": "2023-11-21T11:54:13.476949700Z"
    }
   },
   "id": "5927031663e9e079"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1001平板', '1002手机', '1003耳机', '1004耳机', '1005帽子']\n",
      "已添加到购物车！\n",
      "已添加到购物车！\n",
      "已添加到购物车！\n",
      "您输入的商品编号不存在，请重新输入！\n",
      "您的购物车中有以下商品：\n",
      "1005帽子\n",
      "1002手机\n",
      "1001平板\n"
     ]
    }
   ],
   "source": [
    "info = []\n",
    "for _ in range(0, 5):\n",
    "    tmp = input(\"请输入商品的编号和商品的名称，每次只能输入一个商品：\")\n",
    "    if tmp != \"\":\n",
    "        info.append(tmp)\n",
    "print(info)\n",
    "cart = []\n",
    "while True:\n",
    "    num = input(\"请输入商品的编号：\")\n",
    "    flag = False\n",
    "    if num == \"q\":\n",
    "        break\n",
    "    for item in info:\n",
    "        if num == item[0:4]:\n",
    "            cart.append(item)\n",
    "            flag = True\n",
    "            print(\"已添加到购物车！\")\n",
    "    if not flag:\n",
    "        print(\"您输入的商品编号不存在，请重新输入！\")\n",
    "print(\"您的购物车中有以下商品：\")\n",
    "cart.reverse()\n",
    "for item in cart:\n",
    "    print(item)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-21T12:10:43.159771400Z",
     "start_time": "2023-11-21T12:10:13.798568200Z"
    }
   },
   "id": "d2c027f71e2147b4"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "欢迎使用火车票查询系统！\n",
      "------------------------------\n",
      "您的乘车人信息为： 吕锦辉\n",
      "您选择的车次为： G1566\n",
      "该车次的详细信息为： ['广州', '北京', '2019-10-10 12:00', '2019-10-10 20:00', 2000]\n",
      "您的乘车人信息为： 吕锦辉\n",
      "您的车票信息为： ['广州', '北京', '2019-10-10 12:00', '2019-10-10 20:00', 2000]\n",
      "您的车票已经购买成功，请尽快取票！\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "dict_ticket = {\n",
    "    'G1569': ['北京', '上海', '2019-10-10 08:00', '2019-10-10 10:00', 1200],\n",
    "    'G1570': ['上海', '北京', '2019-10-10 14:00', '2019-10-10 16:00', 1200],\n",
    "    'G1566': ['广州', '北京', '2019-10-10 12:00', '2019-10-10 20:00', 2000]\n",
    "}\n",
    "print(\"欢迎使用火车票查询系统！\")\n",
    "print(\"-\" * 30)\n",
    "users = input(\"请输出乘车人信息：\")\n",
    "print(\"您的乘车人信息为：\", users)\n",
    "car = input(\"请输入要购买的车次：\")\n",
    "if car in dict_ticket.keys():\n",
    "    print(\"您选择的车次为：\", car)\n",
    "    print(\"该车次的详细信息为：\", dict_ticket[car])\n",
    "    print(\"您的乘车人信息为：\", users)\n",
    "    print(\"您的车票信息为：\", dict_ticket[car])\n",
    "    print(\"您的车票已经购买成功，请尽快取票！\")\n",
    "else:\n",
    "    print(\"您输入的车次不存在，请重新输入！\")\n",
    "print(\"-\" * 30)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-21T12:16:08.662290900Z",
     "start_time": "2023-11-21T12:16:02.509549100Z"
    }
   },
   "id": "54f526e9336be4a2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
